*Disclaimer: Generated by Claude Sonnet 4.5, too lazy to write all of this myself.*

# Chat OCR

A modern web application that combines OCR (Optical Character Recognition) capabilities with a chat interface, powered by n8n workflows, Ollama AI, and React.

## Features

- **OCR Processing**: Extract text from images using advanced OCR technology
- **AI-Powered Chat**: Interactive chat interface powered by Ollama
- **Workflow Automation**: Backend powered by n8n for flexible workflow management
- **Modern UI**: Built with React, TypeScript, and Tailwind CSS
- **Responsive Design**: Works seamlessly across devices
- **Docker Support**: Production-ready containerization with nginx

## Prerequisites

Before you begin, ensure you have the following installed:

- **Node.js** (v18 or higher)
- **npm** or **yarn**
- **Docker** and **Docker Compose**
- **Git**

## Installation

### 1. Clone the Repository

```bash
git clone https://github.com/DroidZed/chat-ocr-ui
cd ocr_project
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Configure Environment Variables

Create a `.env` file in the root directory of the project (refer to [.env.example](./.env.example)):

```bash
# Backend API URL (n8n workflow endpoint)
VITE_BACKEND_URL=http://localhost:5678
```

**Important**: Environment variables are embedded during the build process. If you change the backend URL, you'll need to rebuild the application.

### 4. Setup Docker Services

The project uses Docker Compose to run the following backend services:
- **n8n**: Workflow automation platform (port 5678)
- **Ollama**: Local AI model server (port 11434)
- **PostgreSQL**: Database for n8n (port 5432)

```bash
# Create Docker volumes
docker volume create ollama_data
docker volume create n8n_data
docker volume create pg_data

# Start services
docker compose up -d
```

### 5. Verify Services are Running

Check that all services are up:

```bash
docker compose ps
```

You should see three containers running:
- `n8n-workflow`
- `ollama`
- `pg-db`

### 6. Setup Ollama Models (Optional)

If you plan to use Ollama for AI features, pull the required models:

```bash
docker exec -it ollama ollama pull llama2
# Or any other model you prefer (e.g., llama3, mistral, etc.)
```

## Running the Application

### Development Mode

Start the Vite development server:

```bash
npm run dev
```

The application will be available at `http://localhost:3000` (or another port if 5173 is busy).

### Local Production Build

Build the application for production:

```bash
npm run build
```

Preview the production build locally:

```bash
npm run preview
```

### Docker Production Deployment

The application uses a multi-stage Dockerfile that builds the React app and serves it with nginx for optimal performance.

#### Build the Docker Image

```bash
docker build -t ocr-app .
```

#### Run the Container

```bash
docker run -d -p 3000:80 --name ocr-app -e VITE_BACKEND_URL=YOUR_N8N_URL ocr-app
```

Or through compose:

```bash
docker compose up -d
```

The application will be available at `http://localhost:3000`.

#### Build with Custom Backend URL

```bash
# Build the image
docker build -t ocr-app .

# Run the container
docker run -d -p 8080:80 --name ocr-app -e VITE_BACKEND_URL=YOUR_N8N_URL ocr-app
```

#### Stop and Remove the Container

```bash
docker stop ocr-app
docker rm ocr-app
```

#### View Container Logs

```bash
docker logs ocr-app
```

## Accessing Services

- **Frontend (Development)**: http://localhost:3000
- **Frontend (Docker Production)**: http://localhost:8080
- **n8n Workflow Platform**: http://localhost:5678
- **Ollama API**: http://localhost:11434
- **PostgreSQL**: localhost:5432

### n8n Setup

1. Open http://localhost:5678 in your browser
2. Create an account (first-time setup)
3. Import or create your OCR workflows
4. Configure webhook endpoints for the frontend to call

## Project Structure

```
ocr_project/
├── src/
│   ├── components/     # React components
│   ├── core/
│   │   ├── models/     # Data models
│   │   ├── network/    # API configuration (axios)
│   │   ├── schemas/    # Validation schemas
│   │   ├── store/      # State management (Jotai)
│   │   └── utils/      # Utility functions and constants
│   ├── hooks/          # Custom React hooks
│   ├── pages/          # Page components
│   │   ├── LandingPage.tsx
│   │   ├── HomeScreen.tsx
│   │   └── AboutPage.tsx
│   ├── App.tsx
│   └── main.tsx
├── public/             # Static assets
├── Dockerfile          # Multi-stage Docker build
├── nginx.conf          # Nginx configuration for production
├── compose.yml         # Docker Compose for backend services
├── vite.config.ts      # Vite configuration
├── package.json
└── README.md
```

## Stopping the Application

### Stop Development Server

Press `Ctrl+C` in the terminal running the dev server.

### Stopping the compose stack:

```bash
docker compose down
```
## Configuration

### Updating Backend URL

If your backend is hosted elsewhere, update the environment variable before building:

```bash
VITE_BACKEND_URL=https://your-backend-url.com
```

Then rebuild the application:

```bash
# For local development
npm run build

# For Docker deployment
docker build -t ocr-app .
```

### Customizing nginx Configuration

The `nginx.conf` file includes:
- React Router support (client-side routing)
- Gzip compression for better performance
- Security headers
- Static file caching with proper cache control
- Health check endpoint at `/health`

Edit `nginx.conf` to customize these settings.

### Customizing n8n Configuration

Edit `compose.yml` to modify n8n settings such as:
- Timezone
- Database configuration
- Port mappings
- Environment variables

## Available Scripts

- `npm run dev` - Start development server
- `npm run build` - Build for production
- `npm run preview` - Preview production build locally
- `npm run lint` - Run ESLint

## Troubleshooting

### Docker volumes already exist error

If you encounter volume creation errors:

```bash
docker volume ls
# Remove existing volumes if needed
docker volume rm ollama_data n8n_data pg_data
```

### Port already in use

If ports 5678, 11434, 5432, or 8080 are already in use, modify the port mappings:

**For backend services** (compose.yml):
```yaml
ports:
  - "NEW_PORT:CONTAINER_PORT"
```

**For frontend Docker container**:
```bash
docker run -d -p 9090:80 --name ocr-app -e VITE_BACKEND_URL=YOUR_BACKEND_URL ocr-app
```

### Backend connection issues

Ensure:
1. Docker services are running (`docker compose ps`)
2. `VITE_BACKEND_URL` matches your n8n instance URL
3. n8n workflows are properly configured and activated
4. The application was rebuilt after changing environment variables

### nginx 404 errors on refresh

This should be handled by the included `nginx.conf`. If you're still experiencing issues, ensure the nginx configuration is properly copied during the Docker build.

## Docker Architecture

The production Dockerfile uses a multi-stage build:

1. **Build Stage**: Uses Node.js to install dependencies and build the React application
2. **Production Stage**: Uses nginx:alpine to serve the static files

Benefits:
- **Lightweight**: Final image is ~40MB vs ~180MB with Node.js
- **Fast**: nginx is optimized for serving static content
- **Secure**: Minimal attack surface with alpine-based image
- **Production-ready**: Industry standard for SPA deployment

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- [n8n](https://n8n.io/) - Workflow automation platform
- [Ollama](https://ollama.ai/) - Local AI models
- [React](https://react.dev/) - UI framework
- [Vite](https://vitejs.dev/) - Build tool and dev server
- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework
- [nginx](https://nginx.org/) - High-performance web server
